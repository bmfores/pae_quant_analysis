{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44e2999d-988e-466f-aa2b-05ae31f383ba",
   "metadata": {},
   "source": [
    "# Policy Analysis Exercise - Data/Quant Analysis On Migration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79dcbcc8-091e-441f-97ee-ac154b37ccf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5140b2-2500-4359-b2ce-d0eedcd3e771",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part I - Extract US Census Data with API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec46f825-a8fd-42ca-8938-1d9e2f4d559d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your Census API key\n",
    "api_key = \"357c8cd178b67cb9b0aa93664bb6a792f431fc42\"\n",
    "\n",
    "# Ger variables from the American Community Survey\n",
    "# note, this is the only, unfortunately, because this also \n",
    "#includes data for the five previous years, there will be lagging indicators\n",
    "dataset = \"acs/acs5\"\n",
    "\n",
    "## get 2018 to 2022 \n",
    "# NOTE: On 7 December 2022, be sure to add 2022 ACS-5 data\n",
    "years = [\"2018\", \"2019\", \"2020\", \"2021\"]\n",
    "\n",
    "## SELECT YOUR VARIABLES HERE ##\n",
    "variables = (\"B01003_001E,B01001_002E,B01001_026E,B02001_002E,B02001_003E,\"\n",
    "             \"B02001_004E,B02001_005E,B03001_003E,B01002_001E,B19301_001E,\"\n",
    "             \"B19013_001E,B17001_002E,B17001_004E,B08136_001E,B25010_001E,\"\n",
    "             \"B06008_002E,B06008_007E,B13016_001E,B25003_003E,B25003_002E,\"\n",
    "             \"B25077_001E,B15003_017E,B15003_022E,B16001_002E,B05002_013E\")\n",
    "\n",
    "## SCHOOL AGED POPULATION: B01001_004E, B01001_005E, B01001_006E, B01001_028E, B01001_029E, B01001_030E\n",
    "variables += (\",B23025_004E,B23025_005E,B23025_007E,B01001_004E,B01001_005E,\"\n",
    "              \"B01001_006E,B01001_028E,B01001_029E,B01001_030E\")\n",
    "\n",
    "## new variables ##\n",
    "## Theil Index - Census\n",
    "## Male to Female ratio\n",
    "# population density, nonwhite population, native population\n",
    "# voter turnout(?)\n",
    "# average household size, estimated number of families\n",
    "# per capita income, median family income, median household income by race,\n",
    "# poverty rate\n",
    "# percent of families in DEEP poverty, GINI index\n",
    "# SE:B13004:Ratio of Income in 2020 to Poverty Level (Summarized - top-coded at 2.00)\n",
    "# Estimated percent of people 16 to 19 years old \n",
    "    #who were not enrolled in school and were unemployed or not in the labor force, between 2017-2021.\n",
    "#non census variables\n",
    "#IRS, percent of tax returns with nonrefundable education credit\n",
    "#HUD - difficult development area (DDA)\n",
    "\n",
    "# initialize empty dataframe called acs_df\n",
    "acs_df = pd.DataFrame()\n",
    "\n",
    "# loop through all years\n",
    "for year in years:\n",
    "    params = {\n",
    "        \"get\": variables,\n",
    "        \"for\": \"zip code tabulation area:*\",\n",
    "        \"key\": api_key\n",
    "    }\n",
    "    \n",
    "    response = requests.get(f\"https://api.census.gov/data/{year}/{dataset}\", params=params)\n",
    "    data = response.json()\n",
    "    \n",
    "    # Create a DataFrame for the current year and add a 'Year' column\n",
    "    df = pd.DataFrame(data[1:], columns=data[0])\n",
    "    df['year'] = year\n",
    "    \n",
    "    # Append the data for this year to the main DataFrame\n",
    "    acs_df = pd.concat([acs_df, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d6c2d4-157b-492a-9dc2-5c7705df8162",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rename the columns to make them more understandable\n",
    "acs_df.rename(columns={\n",
    "    \"B01003_001E\": \"total_population\",\n",
    "    \"B01001_002E\": \"male_population\",\n",
    "    \"B01001_026E\": \"female_population\",\n",
    "    \"B02001_002E\": \"population_white\",\n",
    "    \"B02001_003E\": \"population_black\",\n",
    "    \"B02001_004E\": \"population_native\",\n",
    "    \"B02001_005E\": \"population_asian\",\n",
    "    \"B03001_003E\": \"population_hispanic\",\n",
    "    \"B01002_001E\": \"median_age\",\n",
    "    \"B19301_001E\": \"per_capita_income\",\n",
    "    \"B19013_001E\": \"median_household_income\",\n",
    "    \"B17001_002E\": \"count_poverty_line\",\n",
    "    \"B17001_004E\": \"count_children_poverty_line\",\n",
    "    \"B08136_001E\": \"mean_commute_time\",\n",
    "    \"B25010_001E\": \"household_size\",\n",
    "    \"B06008_002E\": \"count_married\",\n",
    "    \"B06008_007E\": \"count_single\",\n",
    "    \"B13016_001E\": \"fertility_rate\",\n",
    "    \"B25003_003E\": \"count_renter_occupied\",\n",
    "    \"B25003_002E\": \"count_owner_occupied\",\n",
    "    \"B25077_001E\": \"median_home_value\",\n",
    "    \"B15003_017E\": \"count_hs_grad\",\n",
    "    \"B15003_022E\": \"count_bachelors_degree\",\n",
    "    \"B16001_002E\": \"count_adults_english_at_home\",\n",
    "    \"B05002_013E\": \"count_foreign_born\",\n",
    "    \"B23025_004E\": \"employed_civilian_over_16\",\n",
    "    \"B23025_005E\": \"unemployed_civilian_over_16\",\n",
    "    \"B23025_007E\": \"not_in_labor_force\",\n",
    "    \"B01001_004E\": \"male_under_5_years\",\n",
    "    \"B01001_005E\": \"male_5_to_9_years\",\n",
    "    \"B01001_006E\": \"male_10_to_14_years\",\n",
    "    \"B01001_028E\": \"female_under_5_years\",\n",
    "    \"B01001_029E\": \"female_5_to_9_years\",\n",
    "    \"B01001_030E\": \"female_10_to_14_years\",\n",
    "    \"zip code tabulation area\": \"zip_code\"\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b1dabe-ac78-4ed3-9b0b-2f195016c33b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## print data to see if it works\n",
    "acs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ad3422-aaed-4ccb-9f6a-d4844806b023",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# verify if API call was correct\n",
    "# Number of rows in DataFrame\n",
    "num_rows = len(acs_df)\n",
    "\n",
    "# Number of unique values in 'state' column\n",
    "num_unique_states = acs_df['state'].nunique()\n",
    "\n",
    "# number of rows should be approx 33120*n_years = 132k\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "print(f\"Number of unique states: {num_unique_states}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffe6db9-3924-4a60-b496-173fb9b480b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save to dataset after all changes\n",
    "acs_df.to_csv(\"acs_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dd1cab-c07c-4411-9458-00ed2528e312",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part II - Data Wrangling USPS FOIA NCOA Data\n",
    "\n",
    "Here, I will merge the US Census data to merge with USPS data. Uses Long Format i.e. for every row denotes a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b237e86-b23e-4c02-92db-ae40d33b15a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Concatenate all USPS FOIA NCOA .csv files\n",
    "# path to .csv files\n",
    "path = \"./usps_foia/\"\n",
    "all_files = glob.glob(path + \"Y*.csv\")\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename)\n",
    "    dfs.append(df)\n",
    "\n",
    "ncoa_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2154ea64-1f12-4e21-aba1-c52f004ea0b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ncoa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c129cb07-926e-4d87-9357-9f3668665ff9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## DATA CLEANING\n",
    "# clean year, remove month\n",
    "try:\n",
    "    ncoa_df['year'] = ncoa_df['YYYYMM'].astype(str).str[:4].astype(int)\n",
    "    ncoa_df['month'] = ncoa_df['YYYYMM'].astype(str).str[4:].astype(int)\n",
    "    ncoa_df.drop(columns=['YYYYMM'], inplace=True)\n",
    "except KeyError:\n",
    "    print(\"Column 'YYYYMM' does not exist or has already been renamed.\")\n",
    "\n",
    "# clean zip code\n",
    "try:\n",
    "    ncoa_df['ZIPCODE'] = ncoa_df['ZIPCODE'].str.extract('(\\d+)')\n",
    "    ncoa_df.rename(columns={'ZIPCODE': 'zip_code'}, inplace=True)\n",
    "except KeyError:\n",
    "    print(\"Column 'ZIPCODE' does not exist or has already been renamed.\")\n",
    "\n",
    "# rename columns\n",
    "# change to lowercase first\n",
    "ncoa_df.columns = ncoa_df.columns.str.lower() #change all to lowercase\n",
    "# rename map\n",
    "column_rename_map = {\n",
    "    'state': 'state_abbrev',\n",
    "    'total from zip': 'total_leaving_zip',\n",
    "    'total business': 'total_business_leaving',\n",
    "    'total family': 'total_family_leaving',\n",
    "    'total individual': 'total_individual_leaving',\n",
    "    'total perm': 'total_perm_leaving',\n",
    "    'total temp': 'total_temp_leaving',\n",
    "    'total to zip': 'total_entering_zip',\n",
    "    'total business.1': 'total_business_entering',\n",
    "    'total family.1': 'total_family_entering',\n",
    "    'total individual.1': 'total_individual_entering',\n",
    "    'total perm.1': 'total_perm_entering',\n",
    "    'total temp.1': 'total_temp_entering'\n",
    "}\n",
    "\n",
    "ncoa_df.rename(columns=column_rename_map, inplace=True)\n",
    "\n",
    "# sort by zipcode and year\n",
    "ncoa_df.sort_values(by=['zip_code', 'year'], inplace=True)\n",
    "ncoa_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# change city caps to title form\n",
    "ncoa_df['city'] = ncoa_df['city'].str.title()\n",
    "\n",
    "# rearrange year and month to second and third row\n",
    "cols = ncoa_df.columns.tolist()\n",
    "if cols[1] != 'year' or cols[2] != 'month':\n",
    "    cols.insert(1, cols.pop(cols.index('year')))\n",
    "    cols.insert(2, cols.pop(cols.index('month')))\n",
    "    ncoa_df = ncoa_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4fe171-4c40-49fe-be6a-3a9124d79d11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# each row is broken down by month, let's aggregate them into one year\n",
    "# numbers are summed up, objects get the modal value\n",
    "\n",
    "# Drop the 'month' column\n",
    "ncoa_df.drop(columns='month', inplace=True)\n",
    "\n",
    "# Group by 'zip_code' and 'year', then aggregate the data\n",
    "ncoa_df = ncoa_df.groupby(['zip_code', 'year']).agg({\n",
    "    'city': lambda x: x.mode()[0],  # Most frequent value\n",
    "    'state_abbrev': lambda x: x.mode()[0],  # Most frequent value\n",
    "    'total_leaving_zip': 'sum',\n",
    "    'total_business_leaving': 'sum',\n",
    "    'total_family_leaving': 'sum',\n",
    "    'total_individual_leaving': 'sum',\n",
    "    'total_perm_leaving': 'sum',\n",
    "    'total_temp_leaving': 'sum',\n",
    "    'total_entering_zip': 'sum',\n",
    "    'total_business_entering': 'sum',\n",
    "    'total_family_entering': 'sum',\n",
    "    'total_individual_entering': 'sum',\n",
    "    'total_perm_entering': 'sum',\n",
    "    'total_temp_entering': 'sum'\n",
    "    # Add all other int64 variables here in similar fashion\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878828a1-bd12-4fcc-8876-ec02190e5575",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ncoa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f31d2d-bdae-46b9-96b7-424a86d24238",
   "metadata": {},
   "outputs": [],
   "source": [
    "##ZCTA CROSSWALK ISSUE\n",
    "\n",
    "#https://udsmapper.org/zip-code-to-zcta-crosswalk/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cd2a62-2ec0-4b3b-be99-3436d205b455",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save to dataset after all changes\n",
    "ncoa_df.to_csv(\"ncoa_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecc3f19-4729-48f4-8b2e-28430e8def1b",
   "metadata": {},
   "source": [
    "## Merge NCOA and ACS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce8ff7f-6339-47b1-8864-e143fb7f3385",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ncoa_df = pd.read_csv('ncoa_df.csv')\n",
    "acs_df = pd.read_csv('acs_df.csv')\n",
    "\n",
    "# Make sure the 'zip_code' and 'year' columns are of the same data type in both DataFrames\n",
    "ncoa_df['zip_code'] = ncoa_df['zip_code'].apply(lambda x: str(x).zfill(5))\n",
    "acs_df['zip_code'] = acs_df['zip_code'].apply(lambda x: str(x).zfill(5))\n",
    "ncoa_df['year'] = ncoa_df['year'].astype(int)\n",
    "acs_df['year'] = acs_df['year'].astype(int)\n",
    "\n",
    "# Perform the merge\n",
    "merged_df = pd.merge(ncoa_df, acs_df, how='left', on=['zip_code', 'year'])\n",
    "\n",
    "# Save the merged DataFrame\n",
    "merged_df.to_csv('pae_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e484d43-4fac-47e9-a566-757a23b26584",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# after merging, delete intermediate csvs\n",
    "# identify which files to deleete\n",
    "files_to_delete = ['ncoa_df.csv', 'acs_df.csv']\n",
    "\n",
    "# loop through and delete the files\n",
    "for file_path in files_to_delete:\n",
    "    try:\n",
    "        os.remove(file_path)\n",
    "        print(f\"The file {file_path} has been deleted.\")\n",
    "    except Exception as e:\n",
    "        print(f\"The file {file_path} does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422aef40-94d5-46f0-baa9-90220b38fc02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce158244-ada5-4e6e-b52e-acca14510afb",
   "metadata": {},
   "source": [
    "## FILTER TO BOSTON AND NYC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584d2f1a-e635-4ff9-85cf-534945cd2fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make a smaller dataset with boston and NYC zip codes, then aggregate by year\n",
    "# Boston ZIP Codes - 48 listed\n",
    "boston_zip_codes = [\n",
    "    '02108', '02109', '02110', '02111', '02112', '02113', '02114', '02115', '02116', '02117', '02118', '02119',\n",
    "    '02120', '02121', '02122', '02123', '02124', '02125', '02126', '02127', '02128', '02129', '02130', '02131',\n",
    "    '02132', '02133', '02134', '02135', '02136', '02215', '02199', '02201', '02203', '02204', '02205', '02206',\n",
    "    '02210', '02211', '02212', '02217', '02222', '02266', '02283', '02284', '02293', '02295', '02297', '02298'\n",
    "]\n",
    "\n",
    "# NYC ZIP Codes - 187 listed\n",
    "nyc_zip_codes = [\n",
    "    # Manhattan\n",
    "    '10001', '10002', '10003', '10004', '10005', '10006', '10007', '10009', '10010', '10011', '10012', '10013',\n",
    "    '10014', '10016', '10017', '10018', '10019', '10020', '10021', '10022', '10023', '10024', '10025', '10026',\n",
    "    '10027', '10028', '10029', '10030', '10031', '10032', '10033', '10034', '10035', '10036', '10037', '10038',\n",
    "    '10039', '10040', '10044', '10065', '10069', '10075', '10103', '10110', '10111', '10112', '10115', '10119',\n",
    "    '10128', '10152', '10153', '10154', '10162', '10165', '10167', '10168', '10169', '10170', '10171', '10172',\n",
    "    '10173', '10174', '10177', '10199', '10271', '10278', '10279', '10280', '10282',\n",
    "    \n",
    "    # Brooklyn\n",
    "    '11201', '11203', '11204', '11205', '11206', '11207', '11208', '11209', '11210', '11211', '11212', '11213',\n",
    "    '11214', '11215', '11216', '11217', '11218', '11219', '11220', '11221', '11222', '11223', '11224', '11225',\n",
    "    '11226', '11228', '11229', '11230', '11231', '11232', '11233', '11234', '11235', '11236', '11237', '11238',\n",
    "    '11239',\n",
    "\n",
    "    # Queens\n",
    "    '11004', '11005', '11101', '11102', '11103', '11104', '11105', '11106', '11354', '11355', '11356', '11357',\n",
    "    '11358', '11359', '11360', '11361', '11362', '11363', '11364', '11365', '11366', '11367', '11368', '11369',\n",
    "    '11370', '11371', '11372', '11373', '11374', '11375', '11377', '11378', '11379', '11385', '11411', '11412',\n",
    "    '11413', '11414', '11415', '11416', '11417', '11418', '11419', '11420', '11421', '11422', '11423', '11426',\n",
    "    '11427', '11428', '11429', '11430', '11432', '11433', '11434', '11435', '11436', '11691', '11692', '11693',\n",
    "    '11694', '11697',\n",
    "\n",
    "    # Bronx\n",
    "    '10451', '10452', '10453', '10454', '10455', '10456', '10457', '10458', '10459', '10460', '10461', '10462',\n",
    "    '10463', '10464', '10465', '10466', '10467', '10468', '10469', '10470', '10471', '10472', '10473', '10474',\n",
    "    '10475',\n",
    "\n",
    "    # Staten Island\n",
    "    '10301', '10302', '10303', '10304', '10305', '10306', '10307', '10308', '10309', '10310', '10312', '10314'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198192a9-ccd5-425c-9033-c7538f6a86b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## DROP Non-Boston adn NYC zip codes\n",
    "bos_nyc_df = pd.read_csv('pae_dataset.csv')\n",
    "\n",
    "# #combine boston and nyc zip code lists\n",
    "combined_zip_codes = boston_zip_codes + nyc_zip_codes\n",
    "\n",
    "#make the zip_code column into string first\n",
    "bos_nyc_df['zip_code'] = bos_nyc_df['zip_code'].astype(str).str.zfill(5) \n",
    "\n",
    "# now you can filter them, now that they match data types\n",
    "bos_nyc_df = bos_nyc_df[bos_nyc_df['zip_code'].isin(combined_zip_codes)]\n",
    "\n",
    "# # Save the filtered DataFrame\n",
    "bos_nyc_df.to_csv('pae_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a6c815-1a5a-420a-a23a-799a8850f983",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#check the size to see if it ran correctly\n",
    "num_rows = bos_nyc_df.shape[0]\n",
    "num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ea09e9-ad50-4cd7-b38e-9f087a5fc7df",
   "metadata": {},
   "source": [
    "## TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea512644-28a8-4d20-9ef1-689b4363ea8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# School-Aged population\n",
    "abcdf = pd.read_csv('pae_dataset.csv')\n",
    "\n",
    "# List of columns to sum up\n",
    "columns_to_sum = [\n",
    "    'male_under_5_years', 'male_5_to_9_years', 'male_10_to_14_years', \n",
    "    'female_under_5_years', 'female_5_to_9_years', 'female_10_to_14_years'\n",
    "]\n",
    "\n",
    "# Sum up the values across the specified columns for each row\n",
    "abcdf['school_age_population_5_17'] = abcdf[columns_to_sum].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e81d06c5-e5ab-4dbe-a6e8-b63139895fc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate net change in school-age population\n",
    "# First, sort the DataFrame by 'zip_code' and 'year' to ensure the data is in the right order\n",
    "df = pd.read_csv('pae_dataset.csv')\n",
    "df.sort_values(by=['zip_code', 'year'], inplace=True)\n",
    "\n",
    "# Then, you can calculate the yearly change within each 'zip_code' group\n",
    "df['net_change_school_age_pop'] = df.groupby('zip_code')['school_age_population_5_17'].diff()\n",
    "\n",
    "# If the first year of data for each 'zip_code' now has a missing value for 'net_change_children', \n",
    "# which it will after using diff(), you may want to fill it with zero or another appropriate value\n",
    "df['net_change_school_age_pop'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "423ff911-5c8c-4811-8c7a-059627b31064",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate rate, number of school-aged-children per 1000 residents\n",
    "df['school_aged_pop_per_1000_residents'] = ((df['school_age_population_5_17'] / df['total_population']) * 1000).round(0)\n",
    "\n",
    "# Calculate rate, total family leaving per 1000 residents\n",
    "df['total_family_leaving_per_1000_residents'] = ((df['total_family_leaving'] / df['total_population']) * 1000).round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cb1ccab-ffe9-43bf-bde0-5d066a78092a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sort the DataFrame by 'zip_code' and 'year' to ensure the data is in the right order\n",
    "df.sort_values(by=['zip_code', 'year'], inplace=True)\n",
    "\n",
    "# Calculate the yearly change in 'school_aged_pop_per_1000_residents' within each 'zip_code' group\n",
    "df['net_change_school_age_per_1000'] = df.groupby('zip_code')['school_aged_pop_per_1000_residents'].diff()\n",
    "\n",
    "# Handle the NaN values that will appear for the first entry of each 'zip_code' group after using diff()\n",
    "df['net_change_school_age_per_1000'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a04b59d-c4ec-41aa-bc67-5f04c4bef756",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ensure the DataFrame is sorted by 'zip_code' and 'year'\n",
    "df.sort_values(by=['zip_code', 'year'], inplace=True)\n",
    "\n",
    "# Calculate the net change in 'total_family_leaving_per_1000_residents' from the previous year within each ZIP code group\n",
    "df['net_change_family_leaving_per_1000'] = df.groupby('zip_code')['total_family_leaving_per_1000_residents'].diff()\n",
    "\n",
    "# Optionally, handle the NaN values for the first year in each group\n",
    "df['net_change_family_leaving_per_1000'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2b980f-93cb-4e94-8de5-671614715fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert populations to percentage\n",
    "# create net flows\n",
    "# impute, validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54bfab35-acfd-4df2-abe0-f42964e5d43f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Save the filtered DataFrame\n",
    "df.to_csv('pae_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1b22d3-a70c-4e6e-b213-9ec9ee474635",
   "metadata": {},
   "source": [
    "# EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c55bc8c-58aa-45be-9d1e-d680164d1131",
   "metadata": {},
   "outputs": [],
   "source": [
    "## do your eda here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
